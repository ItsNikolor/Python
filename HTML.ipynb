{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id={\n",
    "  \"Достоевский Ф. М.\": 9150,\n",
    "  \"Роллинс Дж.\": 59396,\n",
    "  \"Фицджеральд Ф. С.\": 28727,\n",
    "  \"Глуховский Д. А.\": 53427,\n",
    "  \"Стругацкий А. Н.\": 26268,\n",
    "  \"Лукьяненко С. В.\": 16626,\n",
    "  \"Фрай М.\": 28927,\n",
    "  \"Хантер Э.\": 37969,\n",
    "  \"Роулинг Дж. К.\": 104832\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loger(func):\n",
    "    import functools\n",
    "    @functools.wraps(func)\n",
    "    def wraper(*argc,**argv):\n",
    "        res = func(*argc,**argv)\n",
    "        with mutex:\n",
    "            global n_processed\n",
    "            n_processed += 1\n",
    "            if n_processed % 10 == 0:\n",
    "                print(f\"\\r{n_processed} objects are processed...\", end='', flush=True)\n",
    "        return res\n",
    "    return wraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@loger\n",
    "def extract_book_info(book_id):\n",
    "    import re\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from functools import reduce \n",
    "    \n",
    "    url='https://www.moscowbooks.ru'+book_id[0]\n",
    "    html=requests.get(url).text\n",
    "    soup=BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    ans=dict()\n",
    "    \n",
    "    ans['ID']=re.search('\\d+',book_id[0])[0]\n",
    "    ans['Автор']=soup.find(class_=\"page-header__author\").text[1:-1]\n",
    "    ans['Название']=book_id[1]\n",
    "    ans['Наличие']='true' if soup.find(class_=\"book__shop-instock\") is None else 'false'\n",
    "    tmp=soup.find(class_=\"book__price\")\n",
    "    ans['Цена']=''.join(re.findall(r'\\d',tmp.text))+' '+re.search(r'\\w*\\.',tmp.text)[0]\n",
    "    \n",
    "    description = soup.find(class_=\"book__description\")\n",
    "    for d in description.find_all(['b','a']):\n",
    "        d.replace_with('')\n",
    "\n",
    "    for br in description.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "\n",
    "    ans['Описание']=re.sub('\\s+', ' ', description.text)[1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ans['Рейтинг']=soup.find(class_=\"book___rating-stars rating-stars rating-stars_lg\")['data-rate']\n",
    "    ans['Обложка']='https://www.moscowbooks.ru'+soup.find(class_=\"book__img book__img_default gallery__img\")['src']\n",
    "    ans['Стикеры']=reduce(lambda x,y:x+';'+y,{i.text for i in soup.find_all(class_=\"label\")},'')[1:]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for side in ['left','right']:\n",
    "        for dl in soup.find(class_=f'book__details-{side}').find_all('dl'):\n",
    "            dt=dl.find_all('dt')\n",
    "            key=re.search('.*:',re.sub('\\s+', ' ', dt[0].text)[1:])[0][:-1]\n",
    "            value=re.sub('\\s+', ' ', dt[1].text)[1:]\n",
    "            ans[key]=value\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(author):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    url_0 = f'https://www.moscowbooks.ru/catalog/author/{author_id[author]}/'\n",
    "    html_0 = requests.get(url_0).text\n",
    "    soup = BeautifulSoup(html_0, 'lxml')\n",
    "    ans=[]\n",
    "    number_of_pages=max(len(soup.find_all(class_='pager__text')),2)\n",
    "    for i in range(1,number_of_pages):\n",
    "        url=url_0+f'?page={i}'\n",
    "        html=requests.get(url).text\n",
    "        soup=BeautifulSoup(html,'lxml')\n",
    "        ans+=[(i['href'],i.text) for i in soup.find_all(class_=\"book-preview__title-link\")]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    from functools import reduce \n",
    "    \n",
    "    with Pool(9) as p:\n",
    "        x=p.map(f,author_id )\n",
    "    x=[element for sublist in x for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 objects are processed..."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    from threading import Lock\n",
    "    import pandas as pd\n",
    "    \n",
    "    mutex = Lock()\n",
    "    n_processed = 0\n",
    "    \n",
    "    with Pool(15) as p:\n",
    "        result = p.map(extract_book_info, x)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "    with open('data/hw_3.csv', mode='w', encoding='utf-8') as f_csv:\n",
    "        df.to_csv(f_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
